\documentclass[a4paper,11pt,notitlepage,fullpage]{article}
%\documentclass{report}

\usepackage{fullpage}
\usepackage[utf8]{inputenc}
%\usepackage[ngerman]{babel}
%\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{mathtools}
\usepackage{listings}
\usepackage{bbm}
%\usepackage{algorithm}
%\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hhline}
\usepackage{amsthm}
\usepackage{cite}
\usepackage{wrapfig}
\usepackage{hyperref}
\usepackage{titling}
\usepackage{color}

\setlength{\droptitle}{-60pt}

\newcommand{\R}{\mathbb R}
\newcommand{\p}[1]{\mathbb P\left[#1\right]}
\newcommand{\E}[1]{\mathbb E\left[#1\right]}
\newcommand{\V}{\mathbb V}
\newcommand{\Vv}[1]{\mathbb V\left[#1\right]}
\newcommand{\cov}{\mathbb Cov}
\newcommand{\Cov}[1]{\mathbb Cov\left[#1\right]}
\newcommand{\F}{\mathcal{F}}
\newcommand{\ind}{\mathbbm{1}}
\newcommand{\indd}[1]{\mathbbm{1}_{#1}}
\newcommand{\norm}[2]{\left|\left|{#1}\right|\right|_{#2}}
\DeclareMathOperator*{\limm}{l.\hspace{-0.18em}i.\hspace{-0.19em}m}


\begin{document}
\author{Florian Bogner}
\title{Stochastische Prozesse - Übung 8}
\maketitle

\begin{enumerate}
\setcounter{enumi}{34}

%35
\item 
\begin{enumerate}
\item Mit Bsp. 23 (1) erkennt man: Der Prozess ist eine Linearkombination aus schwach stationären Prozessen und damit schwach stationär. $\E{x_t} = \mu + 0$ und $\gamma(k) = \Cov{z, z} + \Cov{\epsilon_t, \epsilon_{t+k}} = \gamma^2 + \indd{k=0}\sigma^2$.

\item Die Vorraussetzungen der quadratischen Integrierbarkeit der Folgenglieder und des Grenzwertes folgt aus \emph{schwach stationär}. Damit bleibt zu zeigen:
\begin{align*}
\limm_{T\to\infty}~\bar x_T &\stackrel{!}{=} z \\
\Leftrightarrow 0 &\stackrel{!}{=} \lim_{T\to\infty} \E{(\bar x_T - z)^2} \\
&= \lim_{T\to\infty} \E{\left(\left(\frac{1}{T}\sum_{t=1}^T x_t\right) - z\right)^2} \\
&= \lim_{T\to\infty} \E{\left(\left(\frac{1}{T}\sum_{t=1}^T z + \epsilon_t\right) - z\right)^2} \\
&= \lim_{T\to\infty} \E{\left(\frac{1}{T}\sum_{t=1}^T \epsilon_t\right)^2} \\
&= \lim_{T\to\infty} \frac{1}{T^2} \sum_{t=1}^T \E{\epsilon_t^2} \\
&= \lim_{T\to\infty} \frac{1}{T^2} \sum_{t=1}^T \sigma^2 \\
&= \lim_{T\to\infty} \frac{1}{T} \sigma^2 \\
&= 0
\end{align*}
\qed

Der Schätzer ist konsistent, i.e. $\limm_{T\to\infty}~\bar x_T = \mu$ nur dann wenn $z = \mu$ f.s. ist.
\end{enumerate}

%36
\item Aus der Vorlesung wissen wir, dass $\gamma(k) = \sigma^2 \sum_j b_{j+k}b_j$.
\begin{enumerate}
\item $x_t = \epsilon_t + 0.25 \epsilon_{t-1}$ mit $(\epsilon_t) \sim WN(\sigma^2 = 16)$
\begin{align*}
\gamma(0) &= 16 \cdot (1^2 + 0.25^2) = 17 \\
\gamma(-1) = \gamma(1) &= 16 \cdot (1 \cdot 0.25) = 4 \\
\gamma(k) &= 0~~~\text{sonst.}
\end{align*}

\item $x_t = \epsilon_t + 0.8 \epsilon_{t-1} - 0.4 \epsilon_{t-2} + 0.2 \epsilon_{t-3} - 0.1 \epsilon_{t-4}$ mit $(\epsilon_t) \sim WN(\sigma^2 = 2)$
\begin{align*}
\gamma(0) &= 2 \cdot (1^2 + 0.8^2 + 0.4^2 + 0.2^2 + 0.1^2) = 3.7 \\
\gamma(-1) = \gamma(1) &= 2 \cdot (1 \cdot 0.8+ 0.8 \cdot 0.4 + 0.4 \cdot 0.2 + 0.2 \cdot 0.1) = 2.44 \\
\gamma(-2) = \gamma(2) &= 2 \cdot (1 \cdot 0.4+ 0.8 \cdot 0.2 + 0.4 \cdot 0.1) = 1.2 \\
\gamma(-3) = \gamma(3) &= 2 \cdot (1 \cdot 0.2+ 0.8 \cdot 0.1) = 0.56 \\
\gamma(-4) = \gamma(4) &= 2 \cdot (1 \cdot 0.1) = 0.2 \\
\gamma(k) &= 0~~~\text{sonst.}
\end{align*}

\item $x_t = \epsilon_t + 4 \epsilon_{t-1}$ mit $(\epsilon_t) \sim WN(\sigma^2 = 1)$
\begin{align*}
\gamma(0) &= 1 \cdot (1^2 + 4^2) = 17 \\
\gamma(-1) = \gamma(1) &= 1 \cdot (1 \cdot 4) = 4 \\
\gamma(k) &= 0~~~\text{sonst.}
\end{align*}
\end{enumerate}

%37
\item Laut Formeln aus der VO haben wir:
\begin{align*}
\gamma(0) &= \sigma^2 \cdot (b_0^2 + b_1^2) \\
\gamma(1) &= \sigma^2 \cdot b_0 \cdot b_1 \\
\rho(1) &= \frac{b_0 \cdot b_1}{b_0^2 + b_1^2}
\end{align*}
Mit dem Binomialsatz ergibt sich:
\begin{align*}
0 &\leq (b_0 \pm b_1)^2 \\
&= b_0^2 \pm 2b_0b_1 + b_1^2 \\
\Leftrightarrow \mp 2b_0b_1 &\leq b_0^2 + b_1^2 \\
\Leftrightarrow \mp \frac{b_0 \cdot b_1}{b_0^2 + b_1^2} &\leq \frac{1}{2} \\
\Leftrightarrow |\rho(1)| &\leq \frac{1}{2}
\end{align*}
Gdw. $b := b_0 = b_1$, dann $\rho(1) = \frac{b^2}{2b^2} = \frac{1}{2}$.

Umgekehrt, gdw. $b := b_0 = -b_1$, dann $\rho(1) = \frac{-b^2}{2b^2} = -\frac{1}{2}$.

%38
\item

\end{enumerate}


















\end{document}